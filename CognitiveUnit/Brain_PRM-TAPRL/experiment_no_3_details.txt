##### epoch: 0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 6] 
              artifact to be printed now: [400, 1000] 
          Option creation: -----------------> 
              Options created: [[[1, -1], [0, -1], [0, 0]], [[-1, -1], [1, 1], [1, -1]], [[1, -1], [0, -1], [-1, 0]]], 
              Option states: [[2, 4], [2, 5], [1, 4]],

##### epoch: 0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 6] 
              artifact to be printed now: [400, 1000] 
          Option creation: -----------------> 
              Options created: [[[1, -1], [0, -1], [0, 0]], [[1, 0], [0, -1], [0, 1]], [[0, 1], [1, 1], [-1, 1]]], 
              Option states: [[2, 4], [2, 6], [1, 7]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 6], o_t: [[1, -1], [0, -1], [0, 0]], r: 1.0, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [46.4952815  46.17777968 46.55250209 46.93277841 45.5129229  42.8496776
 46.04014774 47.14645043 47.02088003]
              Q[s_t, a_t] after: [46.4952815  46.17777968 46.55250209 46.93277841 45.5129229  42.8496776
 46.04014774 47.14645043 47.61900829]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 1 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 0], [0, -1], [0, 1]], r: 2.0, s_t+1: [2, 6] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.97394227 46.35811277
 46.92822246 46.9786449  47.69407733]
              Q[s_t, a_t] after: [47.95242883 47.44223924 46.83418486 47.10858739 46.97394227 46.35811277
 46.92822246 46.9786449  47.69407733]
             next state: [2, 6] 
             artifact to be printed next: [450, 1000] 
 ------------------------------------------------------- 

##### epoch: 2 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 6] 
              artifact to be printed now: [450, 1000] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 6], o_t: [[0, 1], [1, 1], [-1, 1]], r: 3.0, s_t+1: [1, 7] 
 
             Q[s_t, a_t] before: [45.41503221 47.04855974 46.92298934 46.6411434  45.34279653 46.39739082
 46.079889   46.6957185  46.83488773]
              Q[s_t, a_t] after: [45.41503221 47.04855974 46.92298934 46.6411434  45.34279653 47.74710918
 46.079889   46.6957185  46.83488773]
             next state: [1, 7] 
             artifact to be printed next: [400, 1050] 
 ------------------------------------------------------- 

##### epoch: 3 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 7] 
              artifact to be printed now: [400, 1050] 
          Option selection: -----------------> 
              Option states: [[2, 4], [2, 6], [1, 7]], 
               Option performance: [8.0, 9.0, 10.0], 
              selected state: [1, 7] 

          Option creation: -----------------> 
              Options created: [[[0, -1], [0, 0]], [[0, -1], [0, 0]], [[0, 0], [0, -1]]], 
              Option states: [[1, 6], [1, 6], [1, 6]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 7], o_t: [[0, -1], [0, 0]], r: 4.0, s_t+1: [1, 6] 
 
             Q[s_t, a_t] before: [46.03685354 46.56245207 42.39124964 45.05449494 45.05449494 42.39124964
 46.09407413 46.47435045 46.03685354]
              Q[s_t, a_t] after: [46.03685354 46.56245207 42.39124964 45.05449494 45.05449494 42.39124964
 46.09407413 46.47435045 48.58983588]
             next state: [1, 6] 
             artifact to be printed next: [400, 1000] 
 ------------------------------------------------------- 

##### epoch: 4 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 6] 
              artifact to be printed now: [400, 1000] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 6], o_t: [[0, -1], [0, 0]], r: 5.0, s_t+1: [1, 6] 
 
             Q[s_t, a_t] before: [46.4952815  46.17777968 46.55250209 46.93277841 45.5129229  42.8496776
 46.04014774 47.14645043 47.61900829]
              Q[s_t, a_t] after: [46.4952815  46.17777968 46.55250209 46.93277841 45.5129229  42.8496776
 46.04014774 47.14645043 49.88091325]
             next state: [1, 6] 
             artifact to be printed next: [400, 1000] 
 ------------------------------------------------------- 

          Option creation: -----------------> 
              Options created: [[[1, -1], [0, -1], [0, 0], [0, 0], [0, 0]], [[-1, 0], [0, -1], [1, 0], [-1, 0], [-1, -1]], [[0, 1], [0, 0], [0, -1], [1, -1], [-1, 0]]], 
              Options states: [[[1, 6], [2, 5], [2, 4], [2, 4], [2, 4], [2, 4]], [[1, 6], [0, 6], [0, 5], [1, 5], [0, 5], [0, 4]], [[1, 6], [1, 7], [1, 7], [1, 6], [2, 5], [1, 5]]], 
              subgoals states: [[2, 4], [0, 4], [1, 5]]

