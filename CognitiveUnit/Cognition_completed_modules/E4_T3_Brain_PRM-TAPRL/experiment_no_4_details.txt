##### epoch: 0.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 2] 
              artifact to be printed now: [400, 800] 
          Option creation: -----------------> 
              Options created: [[[1, 1], [0, 1], [0, 0], [0, 0], [0, 0]], [[0, -1], [0, 1], [1, 1], [1, 1], [-1, 0]], [[1, 0], [0, 0], [0, 1], [0, 1], [0, 1]], [[-1, -1], [1, 1], [1, 1], [0, 1], [0, -1]], [[0, -1], [-1, 0], [1, 1], [0, -1], [1, 0]]], 
              Options states: [[[1, 2], [2, 3], [2, 4], [2, 4], [2, 4], [2, 4]], [[1, 2], [1, 1], [1, 2], [2, 3], [3, 4], [2, 4]], [[1, 2], [2, 2], [2, 2], [2, 3], [2, 4], [2, 5]], [[1, 2], [0, 1], [1, 2], [2, 3], [2, 4], [2, 3]], [[1, 2], [1, 1], [0, 1], [1, 2], [1, 1], [2, 1]]], 
              subgoals states: [[2, 4], [2, 4], [2, 5], [2, 3], [2, 1]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 2], o_t: [[1, 1], [0, 1], [0, 0], [0, 0], [0, 0]], r: 0.231229599159292, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 1.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, -1], [0, 1], [1, 1], [1, 1], [-1, 0]], r: 0.232898834588221, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 2.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 0], [0, 0], [0, 1], [0, 1], [0, 1]], r: 0.198005449779971, s_t+1: [2, 5] 
 
             next state: [2, 5] 
             artifact to be printed next: [450, 950] 
 ------------------------------------------------------- 

##### epoch: 3.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 5] 
              artifact to be printed now: [450, 950] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 5], o_t: [[-1, -1], [1, 1], [1, 1], [0, 1], [0, -1]], r: 0.280201831753517, s_t+1: [2, 3] 
 
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 4.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, -1], [-1, 0], [1, 1], [0, -1], [1, 0]], r: 0.342235722112089, s_t+1: [2, 1] 
 
             next state: [2, 1] 
             artifact to be printed next: [450, 750] 
 ------------------------------------------------------- 

##### epoch: 5.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 1] 
              artifact to be printed now: [450, 750] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[0, 1], [0, 1], [0, 1], [0, 0], [0, 0]], [[1, 1], [0, 1], [0, -1], [-1, 1], [-1, 0]], [[1, 0], [1, 1], [-1, 1], [-1, -1], [1, 0]], [[0, -1], [0, 1], [0, 1], [1, -1], [-1, 0]], [[-1, -1], [0, 1], [0, -1], [-1, 1], [1, -1]]], 
              Options states: [[[2, 1], [2, 2], [2, 3], [2, 4], [2, 4], [2, 4]], [[2, 1], [3, 2], [3, 3], [3, 2], [2, 3], [1, 3]], [[2, 1], [3, 1], [4, 2], [3, 3], [2, 2], [3, 2]], [[2, 1], [2, 0], [2, 1], [2, 2], [3, 1], [2, 1]], [[2, 1], [1, 0], [1, 1], [1, 0], [0, 1], [1, 0]]], 
              subgoals states: [[2, 4], [1, 3], [3, 2], [2, 1], [1, 0]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 1], o_t: [[0, 1], [0, 1], [0, 1], [0, 0], [0, 0]], r: 0.362484193857373, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 6.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 1], [0, 1], [0, -1], [-1, 1], [-1, 0]], r: 0.309697173410559, s_t+1: [1, 3] 
 
             next state: [1, 3] 
             artifact to be printed next: [400, 850] 
 ------------------------------------------------------- 

##### epoch: 7.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 3] 
              artifact to be printed now: [400, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 3], o_t: [[1, 0], [1, 1], [-1, 1], [-1, -1], [1, 0]], r: 0.136172973672627, s_t+1: [3, 2] 
 
             next state: [3, 2] 
             artifact to be printed next: [500, 800] 
 ------------------------------------------------------- 

##### epoch: 8.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 2] 
              artifact to be printed now: [500, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 2], o_t: [[0, -1], [0, 1], [0, 1], [1, -1], [-1, 0]], r: 0.362388467082793, s_t+1: [2, 1] 
 
             next state: [2, 1] 
             artifact to be printed next: [450, 750] 
 ------------------------------------------------------- 

##### epoch: 9.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 1] 
              artifact to be printed now: [450, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 1], o_t: [[-1, -1], [0, 1], [0, -1], [-1, 1], [1, -1]], r: 0.412069491020105, s_t+1: [1, 0] 
 
             next state: [1, 0] 
             artifact to be printed next: [400, 700] 
 ------------------------------------------------------- 

##### epoch: 10.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 0] 
              artifact to be printed now: [400, 700] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[1, 0], [1, 0], [1, 1], [0, 1], [-1, 1]], [[0, 1], [1, 1], [0, 1], [1, 0], [1, 1]], [[-1, 0], [-1, 1], [-1, 1], [1, 1], [-1, 1]], [[1, 0], [-1, -1], [1, 0], [0, -1], [0, -1]], [[0, 0], [1, 0], [0, 0], [-1, -1], [1, 0]]], 
              Options states: [[[1, 0], [2, 0], [3, 0], [4, 1], [4, 2], [3, 3]], [[1, 0], [1, 1], [2, 2], [2, 3], [3, 3], [4, 4]], [[1, 0], [0, 0], [0, 1], [0, 2], [1, 3], [0, 4]], [[1, 0], [2, 0], [1, 0], [2, 0], [2, 0], [2, 0]], [[1, 0], [1, 0], [2, 0], [2, 0], [1, 0], [2, 0]]], 
              subgoals states: [[3, 3], [4, 4], [0, 4], [2, 0], [2, 0]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 0], o_t: [[1, 0], [1, 0], [1, 1], [0, 1], [-1, 1]], r: 0.553420525314006, s_t+1: [3, 3] 
 
             next state: [3, 3] 
             artifact to be printed next: [500, 850] 
 ------------------------------------------------------- 

##### epoch: 11.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 3] 
              artifact to be printed now: [500, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 3], o_t: [[0, 1], [1, 1], [0, 1], [1, 0], [1, 1]], r: 0.422984820576245, s_t+1: [4, 4] 
 
             next state: [4, 4] 
             artifact to be printed next: [550, 900] 
 ------------------------------------------------------- 

##### epoch: 12.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 4] 
              artifact to be printed now: [550, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 4], o_t: [[-1, 0], [-1, 1], [-1, 1], [1, 1], [-1, 1]], r: 0.368366223641568, s_t+1: [0, 4] 
 
             next state: [0, 4] 
             artifact to be printed next: [350, 900] 
 ------------------------------------------------------- 

##### epoch: 13.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [0, 4] 
              artifact to be printed now: [350, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [0, 4], o_t: [[1, 0], [-1, -1], [1, 0], [0, -1], [0, -1]], r: 0.279510944210304, s_t+1: [2, 0] 
 
             next state: [2, 0] 
             artifact to be printed next: [450, 700] 
 ------------------------------------------------------- 

##### epoch: 14.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 0] 
              artifact to be printed now: [450, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 0], o_t: [[0, 0], [1, 0], [0, 0], [-1, -1], [1, 0]], r: 0.77052919643004, s_t+1: [2, 0] 
 
             next state: [2, 0] 
             artifact to be printed next: [450, 700] 
 ------------------------------------------------------- 

##### epoch: 15.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 0] 
              artifact to be printed now: [450, 700] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[1, 0], [1, 1], [0, 1], [-1, 1], [-1, 1]], [[1, 0], [0, 0], [1, 1], [0, 1], [1, 0]], [[1, -1], [-1, -1], [0, 0], [1, 0], [1, 1]], [[-1, -1], [1, 0], [0, 1], [1, 1], [-1, 1]], [[0, 1], [0, -1], [1, 0], [-1, 0], [0, -1]]], 
              Options states: [[[2, 0], [3, 0], [4, 1], [4, 2], [3, 3], [2, 4]], [[2, 0], [3, 0], [3, 0], [4, 1], [4, 2], [5, 2]], [[2, 0], [3, 0], [2, 0], [2, 0], [3, 0], [4, 1]], [[2, 0], [1, 0], [2, 0], [2, 1], [3, 2], [2, 3]], [[2, 0], [2, 1], [2, 0], [3, 0], [2, 0], [2, 0]]], 
              subgoals states: [[2, 4], [5, 2], [4, 1], [2, 3], [2, 0]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 0], o_t: [[1, 0], [1, 1], [0, 1], [-1, 1], [-1, 1]], r: 0.637665485300107, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 16.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 0], [0, 0], [1, 1], [0, 1], [1, 0]], r: 0.312587768997173, s_t+1: [5, 2] 
 
             next state: [5, 2] 
             artifact to be printed next: [600, 800] 
 ------------------------------------------------------- 

##### epoch: 17.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [5, 2] 
              artifact to be printed now: [600, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [5, 2], o_t: [[1, -1], [-1, -1], [0, 0], [1, 0], [1, 1]], r: 0.439221787939462, s_t+1: [4, 1] 
 
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 18.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[-1, -1], [1, 0], [0, 1], [1, 1], [-1, 1]], r: 0.409477287552366, s_t+1: [2, 3] 
 
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 19.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, 1], [0, -1], [1, 0], [-1, 0], [0, -1]], r: 0.252196662993697, s_t+1: [2, 0] 
 
             next state: [2, 0] 
             artifact to be printed next: [450, 700] 
 ------------------------------------------------------- 

##### epoch: 20.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 0] 
              artifact to be printed now: [450, 700] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[1, 0], [1, 1], [0, 1], [-1, 1], [-1, 1]], [[0, 0], [-1, 1], [1, 1], [0, 1], [1, 0]], [[1, 0], [1, 1], [0, 1], [1, 0], [-1, 0]], [[1, 0], [0, 1], [1, 1], [0, 1], [0, -1]], [[0, 0], [0, 0], [-1, -1], [0, 1], [1, -1]]], 
              Options states: [[[2, 0], [3, 0], [4, 1], [4, 2], [3, 3], [2, 4]], [[2, 0], [2, 0], [1, 1], [2, 2], [2, 3], [3, 3]], [[2, 0], [3, 0], [4, 1], [4, 2], [5, 2], [4, 2]], [[2, 0], [3, 0], [3, 1], [4, 2], [4, 3], [4, 2]], [[2, 0], [2, 0], [2, 0], [1, 0], [1, 1], [2, 0]]], 
              subgoals states: [[2, 4], [3, 3], [4, 2], [4, 2], [2, 0]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 0], o_t: [[1, 0], [1, 1], [0, 1], [-1, 1], [-1, 1]], r: 0.495900890488385, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 21.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0], [-1, 1], [1, 1], [0, 1], [1, 0]], r: 0.325088725453694, s_t+1: [3, 3] 
 
             next state: [3, 3] 
             artifact to be printed next: [500, 850] 
 ------------------------------------------------------- 

##### epoch: 22.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 3] 
              artifact to be printed now: [500, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 3], o_t: [[1, 0], [1, 1], [0, 1], [1, 0], [-1, 0]], r: 0.414039667507405, s_t+1: [4, 2] 
 
             next state: [4, 2] 
             artifact to be printed next: [550, 800] 
 ------------------------------------------------------- 

##### epoch: 23.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 2] 
              artifact to be printed now: [550, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 2], o_t: [[1, 0], [0, 1], [1, 1], [0, 1], [0, -1]], r: 0.458752699418918, s_t+1: [4, 2] 
 
             next state: [4, 2] 
             artifact to be printed next: [550, 800] 
 ------------------------------------------------------- 

