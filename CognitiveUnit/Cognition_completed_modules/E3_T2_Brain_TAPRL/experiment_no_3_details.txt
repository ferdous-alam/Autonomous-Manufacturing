##### epoch: 0.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 6] 
              artifact to be printed now: [400, 1000] 
          Option creation: -----------------> 
              Options created: [[[1, -1], [0, -1], [0, 0]], [[1, 1], [1, 1], [1, 1]], [[-1, -1], [-1, -1], [1, 0]]], 
              Option states: [[2, 4], [4, 7], [1, 4]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 6], o_t: [[1, -1], [0, -1], [0, 0]], r: -1.00159742972089, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [46.4952815  46.17777968 46.55250209 46.93277841 45.5129229  42.8496776
 46.04014774 47.14645043 47.02088003]
              Q[s_t, a_t] after: [46.4952815  46.17777968 46.55250209 46.93277841 45.5129229  42.8496776
 46.04014774 47.14645043 46.61820958]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 1.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 1], [1, 1], [1, 1]], r: 0.211320749291315, s_t+1: [4, 7] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.97394227 46.35811277
 46.92822246 46.9786449  47.69407733]
              Q[s_t, a_t] after: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.35811277
 46.92822246 46.9786449  47.69407733]
             next state: [4, 7] 
             artifact to be printed next: [550, 1050] 
 ------------------------------------------------------- 

##### epoch: 2.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 7] 
              artifact to be printed now: [550, 1050] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 7], o_t: [[-1, -1], [-1, -1], [1, 0]], r: -0.279648869462278, s_t+1: [1, 4] 
 
             Q[s_t, a_t] before: [45.81088094 45.83154526 44.99683227 45.30643497 45.30643497 44.99683227
 46.29517915 45.77490325 45.81088094]
              Q[s_t, a_t] after: [45.81088094 45.83154526 44.99683227 45.64902047 45.30643497 44.99683227
 46.29517915 45.77490325 45.81088094]
             next state: [1, 4] 
             artifact to be printed next: [400, 900] 
 ------------------------------------------------------- 

##### epoch: 3.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 4] 
              artifact to be printed now: [400, 900] 
          Option selection: -----------------> 
              Option states: [[2, 4], [4, 7], [1, 4]], 
               Option performance: [0.211320749291315, -0.279648869462278, 0.491112023459973], 
              selected state: [1, 4] 

          Option creation: -----------------> 
              Options created: [[[1, 0], [0, 0]], [[-1, 0], [1, -1]], [[1, 0], [0, 0]]], 
              Option states: [[2, 4], [1, 3], [2, 4]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 4], o_t: [[1, 0], [0, 0]], r: 0.491112023459973, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [45.4026767  45.97278639 44.51779981 46.73864125 46.37134744 45.26504475
 44.84280612 46.48680316 45.87874879]
              Q[s_t, a_t] after: [45.4026767  45.97278639 44.51779981 46.73864125 46.37134744 45.26504475
 44.84280612 46.48680316 46.79349868]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 4.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, 0], [1, -1]], r: 0.286781598820217, s_t+1: [1, 3] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.35811277
 46.92822246 46.9786449  47.69407733]
              Q[s_t, a_t] after: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.35811277
 46.92822246 46.82006135 47.69407733]
             next state: [1, 3] 
             artifact to be printed next: [400, 850] 
 ------------------------------------------------------- 

##### epoch: 5.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 3] 
              artifact to be printed now: [400, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 3], o_t: [[1, 0], [0, 0]], r: 0.164623100398513, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [45.98323501 45.57788956 44.94729234 46.59128938 46.84312747 44.62228604
 44.7979843  45.89918754 46.07727261]
              Q[s_t, a_t] after: [45.98323501 45.57788956 44.94729234 46.59128938 46.84312747 44.62228604
 44.7979843  45.89918754 46.72951613]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 6.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
          Option selection: -----------------> 
              Option states: [[2, 4], [1, 3], [2, 4]], 
               Option performance: [0.286781598820217, 0.164623100398513, 0.250973439296898], 
              selected state: [2, 4] 

          Option creation: -----------------> 
              Options created: [[[0, 0]], [[0, 0]], [[-1, 1]]], 
              Option states: [[2, 4], [2, 4], [1, 5]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0]], r: 0.250973439296898, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.35811277
 46.92822246 46.82006135 47.69407733]
              Q[s_t, a_t] after: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.35811277
 46.92822246 46.82006135 47.58109366]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 7.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0]], r: 0.186006469043751, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.35811277
 46.92822246 46.82006135 47.58109366]
              Q[s_t, a_t] after: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.35811277
 46.92822246 46.82006135 47.43619142]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 8.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, 1]], r: 0.22399255066842, s_t+1: [1, 5] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.35811277
 46.92822246 46.82006135 47.43619142]
              Q[s_t, a_t] after: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.43619142]
             next state: [1, 5] 
             artifact to be printed next: [400, 950] 
 ------------------------------------------------------- 

##### epoch: 9.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 5] 
              artifact to be printed now: [400, 950] 
          Option selection: -----------------> 
              Option states: [[2, 4], [2, 4], [1, 5]], 
               Option performance: [0.186006469043751, 0.22399255066842, -1.20044127505157], 
              selected state: [2, 4] 

          Option creation: -----------------> 
              Options created: [[[0, -1]], [[0, -1]], [[0, -1]]], 
              Option states: [[2, 3], [2, 3], [2, 3]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, -1]], r: -1.20044127505157, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.43619142]
              Q[s_t, a_t] after: [47.32678352 46.59095631 46.83418486 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.43619142]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 10.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, -1]], r: 0.229820501819484, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [47.41425723 46.47031729 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.16241914]
              Q[s_t, a_t] after: [47.41425723 46.82012622 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.16241914]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 11.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, -1]], r: 0.315621340592908, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [47.41425723 46.82012622 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.16241914]
              Q[s_t, a_t] after: [47.41425723 47.03793111 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.16241914]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 12.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
          Option selection: -----------------> 
              Option states: [[2, 3], [2, 3], [2, 3]], 
               Option performance: [0.229820501819484, 0.315621340592908, 0.232323823015554], 
              selected state: [2, 3] 

          Option creation: -----------------> 
              Options created: [[[0, 1], [0, 0]], [[-1, -1], [-1, 0]], [[0, 1], [0, 0]]], 
              Option states: [[2, 4], [0, 2], [2, 4]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, 1], [0, 0]], r: 0.232323823015554, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.41425723 47.03793111 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.16241914]
              Q[s_t, a_t] after: [47.41425723 47.03793111 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.17828624]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 13.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, -1], [-1, 0]], r: 0.203936639945537, s_t+1: [0, 2] 
 
             Q[s_t, a_t] before: [47.32678352 46.59095631 46.83418486 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.43619142]
              Q[s_t, a_t] after: [47.32678352 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.43619142]
             next state: [0, 2] 
             artifact to be printed next: [350, 800] 
 ------------------------------------------------------- 

##### epoch: 14.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [0, 2] 
              artifact to be printed now: [350, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [0, 2], o_t: [[0, 1], [0, 0]], r: 0.12904443485126, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [44.29171576 44.09095122 44.14240772 44.92231298 45.42169603 44.29171576
 44.09095122 44.86159621 44.14240772]
              Q[s_t, a_t] after: [44.29171576 44.09095122 44.14240772 44.92231298 45.42169603 44.29171576
 44.09095122 44.86159621 45.61664083]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 15.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
          Option selection: -----------------> 
              Option states: [[2, 4], [0, 2], [2, 4]], 
               Option performance: [0.203936639945537, 0.12904443485126, 0.285335213254398], 
              selected state: [2, 4] 

          Option creation: -----------------> 
              Options created: [[[0, 0]], [[0, 0]], [[0, 0]]], 
              Option states: [[2, 4], [2, 4], [2, 4]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0]], r: 0.285335213254398, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.43619142]
              Q[s_t, a_t] after: [47.32678352 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.34167807]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 16.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0]], r: 0.20811539992991, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.34167807]
              Q[s_t, a_t] after: [47.32678352 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.20902738]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 17.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0]], r: 0.220349284347362, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.20902738]
              Q[s_t, a_t] after: [47.32678352 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.14144618]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 18.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
          Option selection: -----------------> 
              Option states: [[2, 4], [2, 4], [2, 4]], 
               Option performance: [0.20811539992991, 0.220349284347362, 0.199092864256873], 
              selected state: [2, 4] 

          Option creation: -----------------> 
              Options created: [[[0, 1]], [[1, 1]], [[0, -1]]], 
              Option states: [[2, 5], [3, 5], [2, 3]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 1]], r: 0.199092864256873, s_t+1: [2, 5] 
 
             Q[s_t, a_t] before: [47.32678352 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.14144618]
              Q[s_t, a_t] after: [47.16949487 46.59095631 46.00280028 47.10858739 46.50874519 46.16484043
 46.92822246 46.82006135 47.14144618]
             next state: [2, 5] 
             artifact to be printed next: [450, 950] 
 ------------------------------------------------------- 

##### epoch: 19.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 5] 
              artifact to be printed now: [450, 950] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 5], o_t: [[1, 1]], r: 0.217283389022598, s_t+1: [3, 5] 
 
             Q[s_t, a_t] before: [46.70500727 47.28597309 45.95000854 46.56583804 46.51126295 46.79310889
 46.42608063 46.70048316 46.91867929]
              Q[s_t, a_t] after: [46.70500727 47.28597309 45.95000854 46.56583804 46.57676716 46.79310889
 46.42608063 46.70048316 46.91867929]
             next state: [3, 5] 
             artifact to be printed next: [500, 950] 
 ------------------------------------------------------- 

##### epoch: 20.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 5] 
              artifact to be printed now: [500, 950] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 5], o_t: [[0, -1]], r: 0.192004451916644, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [46.11921712 46.30843733 46.52663346 45.81587178 45.65558323 46.31296144
 46.89392727 46.0366431  46.17379222]
              Q[s_t, a_t] after: [46.11921712 46.72027822 46.52663346 45.81587178 45.65558323 46.31296144
 46.89392727 46.0366431  46.17379222]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 21.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
          Option selection: -----------------> 
              Option states: [[2, 5], [3, 5], [2, 3]], 
               Option performance: [0.217283389022598, 0.192004451916644, 0.233424247665922], 
              selected state: [2, 3] 

          Option creation: -----------------> 
              Options created: [[[0, 1], [0, 1]], [[-1, -1], [-1, 0]], [[-1, 1], [-1, 0]]], 
              Option states: [[2, 5], [0, 2], [0, 4]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, 1], [0, 1]], r: 0.233424247665922, s_t+1: [2, 5] 
 
             Q[s_t, a_t] before: [47.41425723 47.03793111 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.17828624]
              Q[s_t, a_t] after: [47.23039742 47.03793111 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.17828624]
             next state: [2, 5] 
             artifact to be printed next: [450, 950] 
 ------------------------------------------------------- 

##### epoch: 22.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 5] 
              artifact to be printed now: [450, 950] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 5], o_t: [[-1, -1], [-1, 0]], r: 0.238696963558749, s_t+1: [0, 2] 
 
             Q[s_t, a_t] before: [46.70500727 47.28597309 45.95000854 46.56583804 46.57676716 46.79310889
 46.42608063 46.70048316 46.91867929]
              Q[s_t, a_t] after: [46.70500727 47.28597309 45.67458997 46.56583804 46.57676716 46.79310889
 46.42608063 46.70048316 46.91867929]
             next state: [0, 2] 
             artifact to be printed next: [350, 800] 
 ------------------------------------------------------- 

##### epoch: 23.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [0, 2] 
              artifact to be printed now: [350, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [0, 2], o_t: [[-1, 1], [-1, 0]], r: 0.426285149028257, s_t+1: [0, 4] 
 
             Q[s_t, a_t] before: [44.29171576 44.09095122 44.14240772 44.92231298 45.42169603 44.29171576
 44.09095122 44.86159621 45.61664083]
              Q[s_t, a_t] after: [44.29171576 44.09095122 44.67145192 44.92231298 45.42169603 44.29171576
 44.09095122 44.86159621 45.61664083]
             next state: [0, 4] 
             artifact to be printed next: [350, 900] 
 ------------------------------------------------------- 

