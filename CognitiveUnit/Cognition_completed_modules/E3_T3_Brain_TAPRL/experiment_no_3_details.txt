##### epoch: 0.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 1] 
              artifact to be printed now: [500, 750] 
          Option creation: -----------------> 
              Options created: [[[1, 0], [0, 0]], [[1, 0], [0, 1]], [[-1, -1], [-1, 0]]], 
              Option states: [[4, 1], [4, 2], [1, 0]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 1], o_t: [[1, 0], [0, 0]], r: 0.740834358229256, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [46.51801198 47.18479065 45.91641081 47.23005351 47.03966365 46.59406182
 46.74800732 45.75193354 47.12038032]
              Q[s_t, a_t] after: [46.51801198 47.18479065 45.91641081 47.23005351 47.03966365 46.59406182
 46.74800732 45.75193354 47.36980408]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 1.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[1, 0], [0, 1]], r: 0.688737199122613, s_t+1: [4, 2] 
 
             Q[s_t, a_t] before: [47.16152275 45.87379265 47.24223942 46.65178911 46.73376274 46.63987109
 47.30664975 46.56423542 47.35191261]
              Q[s_t, a_t] after: [47.25961229 45.87379265 47.24223942 46.65178911 46.73376274 46.63987109
 47.30664975 46.56423542 47.35191261]
             next state: [4, 2] 
             artifact to be printed next: [550, 800] 
 ------------------------------------------------------- 

##### epoch: 2.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 2] 
              artifact to be printed now: [550, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 2], o_t: [[-1, -1], [-1, 0]], r: 0.205670698171408, s_t+1: [1, 0] 
 
             Q[s_t, a_t] before: [46.27672508 47.14036832 46.4283268  46.52221845 45.90706473 46.73288414
 47.03069513 46.44024482 46.94997846]
              Q[s_t, a_t] after: [46.27672508 47.14036832 46.67397545 46.52221845 45.90706473 46.73288414
 47.03069513 46.44024482 46.94997846]
             next state: [1, 0] 
             artifact to be printed next: [400, 700] 
 ------------------------------------------------------- 

##### epoch: 3.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 0] 
              artifact to be printed now: [400, 700] 
          Option selection: -----------------> 
              Option states: [[4, 1], [4, 2], [1, 0]], 
               Option performance: [0.688737199122613, 0.205670698171408, 0.621219495876543], 
              selected state: [4, 1] 

          Option creation: -----------------> 
              Options created: [[[0, 0]], [[0, -1]], [[0, 0]]], 
              Option states: [[4, 1], [4, 0], [4, 1]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[0, 0]], r: 0.621219495876543, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [47.25961229 45.87379265 47.24223942 46.65178911 46.73376274 46.63987109
 47.30664975 46.56423542 47.35191261]
              Q[s_t, a_t] after: [47.25961229 45.87379265 47.24223942 46.65178911 46.73376274 46.63987109
 47.30664975 46.56423542 47.42576279]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 4.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[0, -1]], r: 0.560629901896055, s_t+1: [4, 0] 
 
             Q[s_t, a_t] before: [47.25961229 45.87379265 47.24223942 46.65178911 46.73376274 46.63987109
 47.30664975 46.56423542 47.42576279]
              Q[s_t, a_t] after: [47.25961229 45.84344204 47.24223942 46.65178911 46.73376274 46.63987109
 47.30664975 46.56423542 47.42576279]
             next state: [4, 0] 
             artifact to be printed next: [550, 700] 
 ------------------------------------------------------- 

##### epoch: 5.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 0] 
              artifact to be printed now: [550, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 0], o_t: [[0, 0]], r: 0.752237624636579, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [45.70955709 44.23143713 45.66429423 44.92187991 45.0094336  45.5998839
 45.66429423 44.92187991 44.23143713]
              Q[s_t, a_t] after: [45.70955709 44.23143713 45.66429423 44.92187991 45.0094336  45.5998839
 45.66429423 44.92187991 45.96758996]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 6.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
          Option selection: -----------------> 
              Option states: [[4, 1], [4, 0], [4, 1]], 
               Option performance: [0.560629901896055, 0.752237624636579, 0.34230379322293], 
              selected state: [4, 0] 

          Option creation: -----------------> 
              Options created: [[[0, 0]], [[-1, -1]], [[1, -1]]], 
              Option states: [[4, 0], [3, 0], [5, 0]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 0], o_t: [[0, 0]], r: 0.34230379322293, s_t+1: [4, 0] 
 
             Q[s_t, a_t] before: [45.70955709 44.23143713 45.66429423 44.92187991 45.0094336  45.5998839
 45.66429423 44.92187991 45.96758996]
              Q[s_t, a_t] after: [45.70955709 44.23143713 45.66429423 44.92187991 45.0094336  45.5998839
 45.66429423 44.92187991 45.90890391]
             next state: [4, 0] 
             artifact to be printed next: [550, 700] 
 ------------------------------------------------------- 

##### epoch: 7.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 0] 
              artifact to be printed now: [550, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 0], o_t: [[-1, -1]], r: 0.667153228147955, s_t+1: [3, 0] 
 
             Q[s_t, a_t] before: [45.70955709 44.23143713 45.66429423 44.92187991 45.0094336  45.5998839
 45.66429423 44.92187991 45.90890391]
              Q[s_t, a_t] after: [45.70955709 44.23143713 45.66429423 44.92187991 45.0094336  45.5998839
 46.5800259  44.92187991 45.90890391]
             next state: [3, 0] 
             artifact to be printed next: [500, 700] 
 ------------------------------------------------------- 

##### epoch: 8.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 0] 
              artifact to be printed now: [500, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[1, -1]], r: 0.774806840173201, s_t+1: [5, 0] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 45.82350058 47.25635768]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.25635768]
             next state: [5, 0] 
             artifact to be printed next: [600, 700] 
 ------------------------------------------------------- 

##### epoch: 9.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [5, 0] 
              artifact to be printed now: [600, 700] 
          Option selection: -----------------> 
              Option states: [[4, 0], [3, 0], [5, 0]], 
               Option performance: [0.667153228147955, 0.774806840173201, 0.247724007758357], 
              selected state: [3, 0] 

          Option creation: -----------------> 
              Options created: [[[1, 1], [0, 0]], [[0, 1], [-1, 1]], [[0, 1], [-1, 0]]], 
              Option states: [[4, 1], [2, 2], [2, 1]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[1, 1], [0, 0]], r: 0.247724007758357, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.25635768]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.22779343]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 10.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[0, 1], [-1, 1]], r: 0.717653880493336, s_t+1: [2, 2] 
 
             Q[s_t, a_t] before: [47.25961229 45.84344204 47.24223942 46.65178911 46.73376274 46.63987109
 47.30664975 46.56423542 47.42576279]
              Q[s_t, a_t] after: [47.25961229 45.84344204 47.24223942 46.65178911 46.73376274 46.7681638
 47.30664975 46.56423542 47.42576279]
             next state: [2, 2] 
             artifact to be printed next: [450, 800] 
 ------------------------------------------------------- 

##### epoch: 11.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 2] 
              artifact to be printed now: [450, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 2], o_t: [[0, 1], [-1, 0]], r: 0.374556080550678, s_t+1: [2, 1] 
 
             Q[s_t, a_t] before: [46.64525518 45.27550233 45.63185536 45.8771035  46.18166085 46.1312384
 45.57113859 46.4794717  45.95315334]
              Q[s_t, a_t] after: [46.64525518 45.27550233 45.71989898 45.8771035  46.18166085 46.1312384
 45.57113859 46.4794717  45.95315334]
             next state: [2, 1] 
             artifact to be printed next: [450, 750] 
 ------------------------------------------------------- 

##### epoch: 12.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 1] 
              artifact to be printed now: [450, 750] 
          Option selection: -----------------> 
              Option states: [[4, 1], [2, 2], [2, 1]], 
               Option performance: [0.717653880493336, 0.374556080550678, 0.46023261906923], 
              selected state: [4, 1] 

          Option creation: -----------------> 
              Options created: [[[0, 0]], [[0, 0]], [[0, -1]]], 
              Option states: [[4, 1], [4, 1], [4, 0]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[0, 0]], r: 0.46023261906923, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [47.25961229 45.84344204 47.24223942 46.65178911 46.73376274 46.7681638
 47.30664975 46.56423542 47.42576279]
              Q[s_t, a_t] after: [47.25961229 45.84344204 47.24223942 46.65178911 46.73376274 46.7681638
 47.30664975 46.56423542 47.41875029]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 13.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[0, 0]], r: 0.566387778245426, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [47.25961229 45.84344204 47.24223942 46.65178911 46.73376274 46.7681638
 47.30664975 46.56423542 47.41875029]
              Q[s_t, a_t] after: [47.25961229 45.84344204 47.24223942 46.65178911 46.73376274 46.7681638
 47.30664975 46.56423542 47.46485043]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 14.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[0, -1]], r: 0.638850183820036, s_t+1: [4, 0] 
 
             Q[s_t, a_t] before: [47.25961229 45.84344204 47.24223942 46.65178911 46.73376274 46.7681638
 47.30664975 46.56423542 47.46485043]
              Q[s_t, a_t] after: [47.25961229 46.29825893 47.24223942 46.65178911 46.73376274 46.7681638
 47.30664975 46.56423542 47.46485043]
             next state: [4, 0] 
             artifact to be printed next: [550, 700] 
 ------------------------------------------------------- 

##### epoch: 15.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 0] 
              artifact to be printed now: [550, 700] 
          Option selection: -----------------> 
              Option states: [[4, 1], [4, 1], [4, 0]], 
               Option performance: [0.566387778245426, 0.638850183820036, 0.686620078456388], 
              selected state: [4, 0] 

          Option creation: -----------------> 
              Options created: [[[-1, -1], [1, 1], [0, 0]], [[-1, -1], [-1, -1], [1, 0]], [[-1, -1], [1, 1], [0, 0]]], 
              Option states: [[4, 1], [3, 0], [4, 1]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 0], o_t: [[-1, -1], [1, 1], [0, 0]], r: 0.686620078456388, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [45.70955709 44.23143713 45.66429423 44.92187991 45.0094336  45.5998839
 46.5800259  44.92187991 45.90890391]
              Q[s_t, a_t] after: [45.70955709 44.23143713 45.66429423 44.92187991 45.0094336  45.5998839
 46.5800259  44.92187991 46.79286295]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 16.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 1], o_t: [[-1, -1], [-1, -1], [1, 0]], r: 0.435590430119091, s_t+1: [3, 0] 
 
             Q[s_t, a_t] before: [47.25961229 46.29825893 47.24223942 46.65178911 46.73376274 46.7681638
 47.30664975 46.56423542 47.46485043]
              Q[s_t, a_t] after: [47.25961229 46.29825893 47.24223942 46.95799194 46.73376274 46.7681638
 47.30664975 46.56423542 47.46485043]
             next state: [3, 0] 
             artifact to be printed next: [500, 700] 
 ------------------------------------------------------- 

##### epoch: 17.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 0] 
              artifact to be printed now: [500, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[-1, -1], [1, 1], [0, 0]], r: 0.91701466325915, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.22779343]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.56750501]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

##### epoch: 18.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 1] 
              artifact to be printed now: [550, 750] 
          Option selection: -----------------> 
              Option states: [[4, 1], [3, 0], [4, 1]], 
               Option performance: [0.435590430119091, 0.91701466325915, 0.351054369625434], 
              selected state: [3, 0] 

          Option creation: -----------------> 
              Options created: [[[0, 0]], [[0, 0]], [[-1, -1]]], 
              Option states: [[3, 0], [3, 0], [2, 0]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[0, 0]], r: 0.351054369625434, s_t+1: [3, 0] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.56750501]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.50519467]
             next state: [3, 0] 
             artifact to be printed next: [500, 700] 
 ------------------------------------------------------- 

##### epoch: 19.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 0] 
              artifact to be printed now: [500, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[0, 0]], r: 0.57991561482058, s_t+1: [3, 0] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.50519467]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.5576265 ]
             next state: [3, 0] 
             artifact to be printed next: [500, 700] 
 ------------------------------------------------------- 

##### epoch: 20.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 0] 
              artifact to be printed now: [500, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[-1, -1]], r: 0.715214746853306, s_t+1: [2, 0] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.81957435 46.305128   47.5576265 ]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.94146588 46.305128   47.5576265 ]
             next state: [2, 0] 
             artifact to be printed next: [450, 700] 
 ------------------------------------------------------- 

##### epoch: 21.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 0] 
              artifact to be printed now: [450, 700] 
          Option selection: -----------------> 
              Option states: [[3, 0], [3, 0], [2, 0]], 
               Option performance: [0.57991561482058, 0.715214746853306, 0.642737586350879], 
              selected state: [3, 0] 

          Option creation: -----------------> 
              Options created: [[[0, 0]], [[0, 0]], [[1, 1]]], 
              Option states: [[3, 0], [3, 0], [4, 1]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[0, 0]], r: 0.642737586350879, s_t+1: [3, 0] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.94146588 46.305128   47.5576265 ]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.94146588 46.305128   47.64120716]
             next state: [3, 0] 
             artifact to be printed next: [500, 700] 
 ------------------------------------------------------- 

##### epoch: 22.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 0] 
              artifact to be printed now: [500, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[0, 0]], r: 0.646726710169224, s_t+1: [3, 0] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.94146588 46.305128   47.64120716]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.94146588 46.305128   47.72636448]
             next state: [3, 0] 
             artifact to be printed next: [500, 700] 
 ------------------------------------------------------- 

##### epoch: 23.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 0] 
              artifact to be printed now: [500, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[1, 1]], r: 0.577001858712742, s_t+1: [4, 1] 
 
             Q[s_t, a_t] before: [47.19194735 47.25635768 46.81957435 45.82350058 47.30162054 45.98797784
 46.94146588 46.305128   47.72636448]
              Q[s_t, a_t] after: [47.19194735 47.25635768 46.81957435 45.82350058 47.43441216 45.98797784
 46.94146588 46.305128   47.72636448]
             next state: [4, 1] 
             artifact to be printed next: [550, 750] 
 ------------------------------------------------------- 

