##### epoch: 0.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 2] 
              artifact to be printed now: [400, 800] 
          Option creation: -----------------> 
              Options created: [[[1, 1], [0, 1], [0, 0]], [[0, 0], [1, 1], [-1, 1]], [[1, 1], [0, 1], [1, -1]]], 
              Option states: [[2, 4], [1, 4], [3, 3]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 2], o_t: [[1, 1], [0, 1], [0, 0]], r: 0.206323168515219, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [45.77424065 45.21414084 44.49495235 45.59615558 46.28825743 44.64426038
 44.44349584 44.91850457 45.27485761]
              Q[s_t, a_t] after: [45.77424065 45.21414084 44.49495235 45.59615558 46.28825743 44.64426038
 44.44349584 44.91850457 46.34915866]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 1.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0], [1, 1], [-1, 1]], r: 0.234411450474244, s_t+1: [1, 4] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.97394227 46.35811277
 46.92822246 46.9786449  47.69407733]
              Q[s_t, a_t] after: [47.32678352 47.44223924 46.83418486 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.69407733]
             next state: [1, 4] 
             artifact to be printed next: [400, 900] 
 ------------------------------------------------------- 

##### epoch: 2.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 4] 
              artifact to be printed now: [400, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 4], o_t: [[1, 1], [0, 1], [1, -1]], r: 0.0772842162603715, s_t+1: [3, 3] 
 
             Q[s_t, a_t] before: [45.4026767  45.97278639 44.51779981 46.73864125 46.37134744 45.26504475
 44.84280612 46.48680316 45.87874879]
              Q[s_t, a_t] after: [45.4026767  45.97278639 44.51779981 46.73864125 46.37134744 45.26504475
 44.84280612 46.49712413 45.87874879]
             next state: [3, 3] 
             artifact to be printed next: [500, 850] 
 ------------------------------------------------------- 

##### epoch: 3.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 3] 
              artifact to be printed now: [500, 850] 
          Option selection: -----------------> 
              Option states: [[2, 4], [1, 4], [3, 3]], 
               Option performance: [0.234411450474244, 0.0772842162603715, 0.432843412712048], 
              selected state: [3, 3] 

          Option creation: -----------------> 
              Options created: [[[-1, 1], [0, 0]], [[1, 1], [-1, 0]], [[1, -1], [1, -1]]], 
              Option states: [[2, 4], [3, 4], [5, 1]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 3], o_t: [[-1, 1], [0, 0]], r: 0.432843412712048, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [46.31366248 45.87916265 46.64731432 45.72756093 46.04186825 46.89915241
 45.95521248 46.40081431 46.18371999]
              Q[s_t, a_t] after: [46.31366248 45.87916265 46.64731432 45.72756093 46.04186825 46.89915241
 45.95521248 46.40081431 46.91684998]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 4.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 1], [-1, 0]], r: 0.244974869597708, s_t+1: [3, 4] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.83418486 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.69407733]
              Q[s_t, a_t] after: [47.32678352 47.44223924 46.82612868 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.69407733]
             next state: [3, 4] 
             artifact to be printed next: [500, 900] 
 ------------------------------------------------------- 

##### epoch: 5.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 4] 
              artifact to be printed now: [500, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 4], o_t: [[1, -1], [1, -1]], r: 0.272664164789364, s_t+1: [5, 1] 
 
             Q[s_t, a_t] before: [46.3233979  46.32810053 47.04353295 46.18624879 45.96547747 46.67623915
 46.79169487 45.87194147 46.45804302]
              Q[s_t, a_t] after: [46.3233979  46.32810053 47.04353295 46.18624879 45.96547747 46.67623915
 46.79169487 46.12643163 46.45804302]
             next state: [5, 1] 
             artifact to be printed next: [600, 750] 
 ------------------------------------------------------- 

##### epoch: 6.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [5, 1] 
              artifact to be printed now: [600, 750] 
          Option selection: -----------------> 
              Option states: [[2, 4], [3, 4], [5, 1]], 
               Option performance: [0.244974869597708, 0.272664164789364, 0.248231894707536], 
              selected state: [3, 4] 

          Option creation: -----------------> 
              Options created: [[[-1, 0], [0, 0]], [[-1, 0], [0, 0]], [[0, 0], [-1, 0]]], 
              Option states: [[2, 4], [2, 4], [2, 4]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 4], o_t: [[-1, 0], [0, 0]], r: 0.248231894707536, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [46.3233979  46.32810053 47.04353295 46.18624879 45.96547747 46.67623915
 46.79169487 46.12643163 46.45804302]
              Q[s_t, a_t] after: [46.3233979  46.32810053 47.04353295 46.18624879 45.96547747 46.67623915
 46.79169487 46.12643163 46.96170573]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 7.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, 0], [0, 0]], r: 0.20073277290898, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.82612868 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.69407733]
              Q[s_t, a_t] after: [47.32678352 47.44223924 46.82612868 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.55597333]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 8.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0], [-1, 0]], r: 0.220983358268568, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 46.82612868 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.55597333]
              Q[s_t, a_t] after: [47.32678352 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.55597333]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 9.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
          Option selection: -----------------> 
              Option states: [[2, 4], [2, 4], [2, 4]], 
               Option performance: [0.20073277290898, 0.220983358268568, 0.260737551311752], 
              selected state: [2, 4] 

          Option creation: -----------------> 
              Options created: [[[0, 0]], [[-1, -1]], [[0, 1]]], 
              Option states: [[2, 4], [1, 3], [2, 5]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0]], r: 0.260737551311752, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.55597333]
              Q[s_t, a_t] after: [47.32678352 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.44856223]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 10.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, -1]], r: 0.0862958571717665, s_t+1: [1, 3] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.92822246 46.9786449  47.44856223]
              Q[s_t, a_t] after: [47.32678352 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.69460726 46.9786449  47.44856223]
             next state: [1, 3] 
             artifact to be printed next: [400, 850] 
 ------------------------------------------------------- 

##### epoch: 11.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 3] 
              artifact to be printed now: [400, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 3], o_t: [[0, 1]], r: 0.359181780940864, s_t+1: [2, 5] 
 
             Q[s_t, a_t] before: [45.98323501 45.57788956 44.94729234 46.59128938 46.84312747 44.62228604
 44.7979843  45.89918754 46.07727261]
              Q[s_t, a_t] after: [46.57776508 45.57788956 44.94729234 46.59128938 46.84312747 44.62228604
 44.7979843  45.89918754 46.07727261]
             next state: [2, 5] 
             artifact to be printed next: [450, 950] 
 ------------------------------------------------------- 

##### epoch: 12.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 5] 
              artifact to be printed now: [450, 950] 
          Option selection: -----------------> 
              Option states: [[2, 4], [1, 3], [2, 5]], 
               Option performance: [0.0862958571717665, 0.359181780940864, 0.208628835766502], 
              selected state: [1, 3] 

          Option creation: -----------------> 
              Options created: [[[1, 1], [0, 0]], [[1, 1], [0, 0]], [[1, -1], [0, 1]]], 
              Option states: [[2, 4], [2, 4], [2, 3]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 3], o_t: [[1, 1], [0, 0]], r: 0.208628835766502, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [46.57776508 45.57788956 44.94729234 46.59128938 46.84312747 44.62228604
 44.7979843  45.89918754 46.07727261]
              Q[s_t, a_t] after: [46.57776508 45.57788956 44.94729234 46.59128938 46.84312747 44.62228604
 44.7979843  45.89918754 46.62998903]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 13.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 1], [0, 0]], r: 0.173210696192342, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.69460726 46.9786449  47.44856223]
              Q[s_t, a_t] after: [47.32678352 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.69460726 46.9786449  47.29792477]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 14.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, -1], [0, 1]], r: 0.178385259313482, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [47.32678352 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.69460726 46.9786449  47.29792477]
              Q[s_t, a_t] after: [47.22264172 47.44223924 47.06376281 47.10858739 46.97394227 46.43188953
 46.69460726 46.9786449  47.29792477]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 15.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
          Option selection: -----------------> 
              Option states: [[2, 4], [2, 4], [2, 3]], 
               Option performance: [0.173210696192342, 0.178385259313482, 0.337901462512537], 
              selected state: [2, 3] 

          Option creation: -----------------> 
              Options created: [[[0, 1], [0, -1]], [[1, 0], [0, 0]], [[-1, 0], [0, 0]]], 
              Option states: [[2, 3], [3, 3], [1, 3]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, 1], [0, -1]], r: 0.337901462512537, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [47.41425723 46.47031729 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.16241914]
              Q[s_t, a_t] after: [47.41425723 46.87416671 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.16241914]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 16.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[1, 0], [0, 0]], r: 0.275301228545902, s_t+1: [3, 3] 
 
             Q[s_t, a_t] before: [47.41425723 46.87416671 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 47.16241914]
              Q[s_t, a_t] after: [47.41425723 46.87416671 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 46.94270092]
             next state: [3, 3] 
             artifact to be printed next: [500, 850] 
 ------------------------------------------------------- 

##### epoch: 17.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 3] 
              artifact to be printed now: [500, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 3], o_t: [[-1, 0], [0, 0]], r: 0.387848492430984, s_t+1: [1, 3] 
 
             Q[s_t, a_t] before: [46.31366248 45.87916265 46.64731432 45.72756093 46.04186825 46.89915241
 45.95521248 46.40081431 46.91684998]
              Q[s_t, a_t] after: [46.31366248 45.87916265 46.64731432 45.72756093 46.04186825 46.89915241
 45.95521248 46.40081431 46.83969734]
             next state: [1, 3] 
             artifact to be printed next: [400, 850] 
 ------------------------------------------------------- 

##### epoch: 18.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 3] 
              artifact to be printed now: [400, 850] 
          Option selection: -----------------> 
              Option states: [[2, 3], [3, 3], [1, 3]], 
               Option performance: [0.275301228545902, 0.387848492430984, 0.262896692422058], 
              selected state: [3, 3] 

          Option creation: -----------------> 
              Options created: [[[-1, 1], [0, -1]], [[0, -1], [-1, 1]], [[-1, 1], [0, -1]]], 
              Option states: [[2, 3], [2, 3], [2, 3]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 3], o_t: [[-1, 1], [0, -1]], r: 0.262896692422058, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [46.31366248 45.87916265 46.64731432 45.72756093 46.04186825 46.89915241
 45.95521248 46.40081431 46.83969734]
              Q[s_t, a_t] after: [46.31366248 46.541087   46.64731432 45.72756093 46.04186825 46.89915241
 45.95521248 46.40081431 46.83969734]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 19.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, -1], [-1, 1]], r: 0.295803220577271, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [47.41425723 46.87416671 46.64840236 46.69882481 46.82876729 46.55436476
 46.14901932 46.39426746 46.94270092]
              Q[s_t, a_t] after: [47.41425723 46.87416671 46.64840236 46.69882481 46.82876729 46.89514132
 46.14901932 46.39426746 46.94270092]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 20.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[-1, 1], [0, -1]], r: 0.239679099532862, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [47.41425723 46.87416671 46.64840236 46.69882481 46.82876729 46.89514132
 46.14901932 46.39426746 46.94270092]
              Q[s_t, a_t] after: [47.41425723 47.02698023 46.64840236 46.69882481 46.82876729 46.89514132
 46.14901932 46.39426746 46.94270092]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 21.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
          Option selection: -----------------> 
              Option states: [[2, 3], [2, 3], [2, 3]], 
               Option performance: [0.295803220577271, 0.239679099532862, 0.240367197938016], 
              selected state: [2, 3] 

          Option creation: -----------------> 
              Options created: [[[0, 1], [0, -1]], [[1, 1], [1, 1]], [[1, 0], [-1, 1]]], 
              Option states: [[2, 3], [4, 5], [2, 4]],

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[0, 1], [0, -1]], r: 0.240367197938016, s_t+1: [2, 3] 
 
             Q[s_t, a_t] before: [47.41425723 47.02698023 46.64840236 46.69882481 46.82876729 46.89514132
 46.14901932 46.39426746 46.94270092]
              Q[s_t, a_t] after: [47.41425723 47.10373104 46.64840236 46.69882481 46.82876729 46.89514132
 46.14901932 46.39426746 46.94270092]
             next state: [2, 3] 
             artifact to be printed next: [450, 850] 
 ------------------------------------------------------- 

##### epoch: 22.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 3] 
              artifact to be printed now: [450, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 3], o_t: [[1, 1], [1, 1]], r: 0.290701519216775, s_t+1: [4, 5] 
 
             Q[s_t, a_t] before: [47.41425723 47.10373104 46.64840236 46.69882481 46.82876729 46.89514132
 46.14901932 46.39426746 46.94270092]
              Q[s_t, a_t] after: [47.41425723 47.10373104 46.64840236 46.69882481 46.57537216 46.89514132
 46.14901932 46.39426746 46.94270092]
             next state: [4, 5] 
             artifact to be printed next: [550, 950] 
 ------------------------------------------------------- 

##### epoch: 23.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 5] 
              artifact to be printed now: [550, 950] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 5], o_t: [[1, 0], [-1, 1]], r: 0.580909458625844, s_t+1: [2, 4] 
 
             Q[s_t, a_t] before: [45.84338379 46.22444367 46.36159278 46.13566447 45.78674178 46.30701768
 46.4962379  46.21914075 46.00367234]
              Q[s_t, a_t] after: [45.84338379 46.22444367 46.36159278 46.13566447 45.78674178 46.92787199
 46.4962379  46.21914075 46.00367234]
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

