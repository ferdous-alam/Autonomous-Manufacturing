##### epoch: 0.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 6] 
              artifact to be printed now: [400, 1000] 
          Option creation: -----------------> 
              Options created: [[[1, -1], [0, -1], [0, 0]], [[1, 1], [-1, -1], [-1, 0]], [[0, 0], [-1, -1], [1, 1]], [[0, 1], [0, -1], [1, 0]]], 
              Options states: [[[1, 6], [2, 5], [2, 4], [2, 4]], [[1, 6], [2, 7], [1, 6], [0, 6]], [[1, 6], [1, 6], [0, 5], [1, 6]], [[1, 6], [1, 7], [1, 6], [2, 6]]], 
              subgoals states: [[2, 4], [0, 6], [1, 6], [2, 6]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 6], o_t: [[1, -1], [0, -1], [0, 0]], r: 0.526382269071169, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 1.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 1], [-1, -1], [-1, 0]], r: 0.175254289982935, s_t+1: [0, 6] 
 
             next state: [0, 6] 
             artifact to be printed next: [350, 1000] 
 ------------------------------------------------------- 

##### epoch: 2.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [0, 6] 
              artifact to be printed now: [350, 1000] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [0, 6], o_t: [[0, 0], [-1, -1], [1, 1]], r: -0.0606722247127807, s_t+1: [1, 6] 
 
             next state: [1, 6] 
             artifact to be printed next: [400, 1000] 
 ------------------------------------------------------- 

##### epoch: 3.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 6] 
              artifact to be printed now: [400, 1000] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 6], o_t: [[0, 1], [0, -1], [1, 0]], r: 0.353531058762091, s_t+1: [2, 6] 
 
             next state: [2, 6] 
             artifact to be printed next: [450, 1000] 
 ------------------------------------------------------- 

##### epoch: 4.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 6] 
              artifact to be printed now: [450, 1000] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[0, -1], [0, -1], [0, 0]], [[-1, 1], [-1, 0], [1, 1]], [[0, -1], [1, 1], [1, 1]], [[1, 1], [-1, -1], [0, -1]]], 
              Options states: [[[2, 6], [2, 5], [2, 4], [2, 4]], [[2, 6], [1, 7], [0, 7], [1, 7]], [[2, 6], [2, 5], [3, 6], [4, 7]], [[2, 6], [3, 7], [2, 6], [2, 5]]], 
              subgoals states: [[2, 4], [1, 7], [4, 7], [2, 5]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 6], o_t: [[0, -1], [0, -1], [0, 0]], r: 0.472052522653104, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 5.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, 1], [-1, 0], [1, 1]], r: 0.167578196415262, s_t+1: [1, 7] 
 
             next state: [1, 7] 
             artifact to be printed next: [400, 1050] 
 ------------------------------------------------------- 

##### epoch: 6.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 7] 
              artifact to be printed now: [400, 1050] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 7], o_t: [[0, -1], [1, 1], [1, 1]], r: -1.04429584521282, s_t+1: [4, 7] 
 
             next state: [4, 7] 
             artifact to be printed next: [550, 1050] 
 ------------------------------------------------------- 

##### epoch: 7.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 7] 
              artifact to be printed now: [550, 1050] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 7], o_t: [[1, 1], [-1, -1], [0, -1]], r: -0.551345997140257, s_t+1: [2, 5] 
 
             next state: [2, 5] 
             artifact to be printed next: [450, 950] 
 ------------------------------------------------------- 

##### epoch: 8.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 5] 
              artifact to be printed now: [450, 950] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[0, -1], [0, 0], [0, 0]], [[0, 0], [0, -1], [0, 0]], [[1, -1], [-1, 1], [-1, 1]], [[-1, -1], [-1, -1], [0, 0]]], 
              Options states: [[[2, 5], [2, 4], [2, 4], [2, 4]], [[2, 5], [2, 5], [2, 4], [2, 4]], [[2, 5], [3, 4], [2, 5], [1, 6]], [[2, 5], [1, 4], [0, 3], [0, 3]]], 
              subgoals states: [[2, 4], [2, 4], [1, 6], [0, 3]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 5], o_t: [[0, -1], [0, 0], [0, 0]], r: 0.337957194101117, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 9.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0], [0, -1], [0, 0]], r: 0.233078983051468, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 10.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, -1], [-1, 1], [-1, 1]], r: 0.134923284670255, s_t+1: [1, 6] 
 
             next state: [1, 6] 
             artifact to be printed next: [400, 1000] 
 ------------------------------------------------------- 

##### epoch: 11.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 6] 
              artifact to be printed now: [400, 1000] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 6], o_t: [[-1, -1], [-1, -1], [0, 0]], r: 0.482221634310447, s_t+1: [0, 3] 
 
             next state: [0, 3] 
             artifact to be printed next: [350, 850] 
 ------------------------------------------------------- 

##### epoch: 12.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [0, 3] 
              artifact to be printed now: [350, 850] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[1, 0], [1, 1], [0, 0]], [[-1, 0], [1, 0], [1, 1]], [[-1, -1], [1, 1], [-1, 1]], [[0, -1], [-1, -1], [1, 1]]], 
              Options states: [[[0, 3], [1, 3], [2, 4], [2, 4]], [[0, 3], [0, 3], [1, 3], [2, 4]], [[0, 3], [0, 2], [1, 3], [0, 4]], [[0, 3], [0, 2], [0, 1], [1, 2]]], 
              subgoals states: [[2, 4], [2, 4], [0, 4], [1, 2]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [0, 3], o_t: [[1, 0], [1, 1], [0, 0]], r: -1.78232265350496, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 13.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, 0], [1, 0], [1, 1]], r: -0.720358338433461, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 14.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, -1], [1, 1], [-1, 1]], r: 0.201178410977633, s_t+1: [0, 4] 
 
             next state: [0, 4] 
             artifact to be printed next: [350, 900] 
 ------------------------------------------------------- 

##### epoch: 15.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [0, 4] 
              artifact to be printed now: [350, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [0, 4], o_t: [[0, -1], [-1, -1], [1, 1]], r: -1.46073975230905, s_t+1: [1, 2] 
 
             next state: [1, 2] 
             artifact to be printed next: [400, 800] 
 ------------------------------------------------------- 

##### epoch: 16.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 2] 
              artifact to be printed now: [400, 800] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[1, 1], [0, 1], [0, 0]], [[1, 1], [-1, 0], [0, 0]], [[1, -1], [0, -1], [1, 0]], [[1, 0], [0, 1], [0, 1]]], 
              Options states: [[[1, 2], [2, 3], [2, 4], [2, 4]], [[1, 2], [2, 3], [1, 3], [1, 3]], [[1, 2], [2, 1], [2, 0], [3, 0]], [[1, 2], [2, 2], [2, 3], [2, 4]]], 
              subgoals states: [[2, 4], [1, 3], [3, 0], [2, 4]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 2], o_t: [[1, 1], [0, 1], [0, 0]], r: 0.296359549334973, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 17.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 1], [-1, 0], [0, 0]], r: 0.310043243339669, s_t+1: [1, 3] 
 
             next state: [1, 3] 
             artifact to be printed next: [400, 850] 
 ------------------------------------------------------- 

##### epoch: 18.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 3] 
              artifact to be printed now: [400, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 3], o_t: [[1, -1], [0, -1], [1, 0]], r: 0.246197569428356, s_t+1: [3, 0] 
 
             next state: [3, 0] 
             artifact to be printed next: [500, 700] 
 ------------------------------------------------------- 

##### epoch: 19.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 0] 
              artifact to be printed now: [500, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[1, 0], [0, 1], [0, 1]], r: 0.728592109322649, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 20.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[0, 0], [0, 0], [0, 0]], [[-1, -1], [-1, -1], [1, 1]], [[-1, 1], [1, -1], [-1, 1]], [[0, 0], [-1, 0], [-1, 1]]], 
              Options states: [[[2, 4], [2, 4], [2, 4], [2, 4]], [[2, 4], [1, 3], [0, 2], [1, 3]], [[2, 4], [1, 5], [2, 4], [1, 5]], [[2, 4], [2, 4], [1, 4], [0, 5]]], 
              subgoals states: [[2, 4], [1, 3], [1, 5], [0, 5]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0], [0, 0], [0, 0]], r: 0.575809987763182, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 21.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, -1], [-1, -1], [1, 1]], r: 0.515147571826068, s_t+1: [1, 3] 
 
             next state: [1, 3] 
             artifact to be printed next: [400, 850] 
 ------------------------------------------------------- 

##### epoch: 22.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 3] 
              artifact to be printed now: [400, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 3], o_t: [[-1, 1], [1, -1], [-1, 1]], r: 0.0606933364105453, s_t+1: [1, 5] 
 
             next state: [1, 5] 
             artifact to be printed next: [400, 950] 
 ------------------------------------------------------- 

##### epoch: 23.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 5] 
              artifact to be printed now: [400, 950] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 5], o_t: [[0, 0], [-1, 0], [-1, 1]], r: -0.660718940224441, s_t+1: [0, 5] 
 
             next state: [0, 5] 
             artifact to be printed next: [350, 950] 
 ------------------------------------------------------- 

