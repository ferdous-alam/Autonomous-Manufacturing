##### epoch: 0.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 1] 
              artifact to be printed now: [500, 750] 
          Option creation: -----------------> 
              Options created: [[[1, 1], [-1, 1], [-1, 1], [0, 0], [0, 0]], [[1, 1], [0, 0], [-1, 1], [0, 0], [0, 0]], [[-1, 0], [0, 0], [-1, -1], [1, -1], [1, -1]], [[0, -1], [1, 1], [-1, -1], [-1, 0], [-1, -1]], [[1, 1], [-1, 1], [0, 0], [-1, 1], [0, 0]]], 
              Options states: [[[3, 1], [4, 2], [3, 3], [2, 4], [2, 4], [2, 4]], [[3, 1], [4, 2], [4, 2], [3, 3], [3, 3], [3, 3]], [[3, 1], [2, 1], [2, 1], [1, 0], [2, 0], [3, 0]], [[3, 1], [3, 0], [4, 1], [3, 0], [2, 0], [1, 0]], [[3, 1], [4, 2], [3, 3], [3, 3], [2, 4], [2, 4]]], 
              subgoals states: [[2, 4], [3, 3], [3, 0], [1, 0], [2, 4]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 1], o_t: [[1, 1], [-1, 1], [-1, 1], [0, 0], [0, 0]], r: 0.682459134754758, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 1.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 1], [0, 0], [-1, 1], [0, 0], [0, 0]], r: 0.218219405848038, s_t+1: [3, 3] 
 
             next state: [3, 3] 
             artifact to be printed next: [500, 850] 
 ------------------------------------------------------- 

##### epoch: 2.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 3] 
              artifact to be printed now: [500, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 3], o_t: [[-1, 0], [0, 0], [-1, -1], [1, -1], [1, -1]], r: 0.493781602696458, s_t+1: [3, 0] 
 
             next state: [3, 0] 
             artifact to be printed next: [500, 700] 
 ------------------------------------------------------- 

##### epoch: 3.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 0] 
              artifact to be printed now: [500, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 0], o_t: [[0, -1], [1, 1], [-1, -1], [-1, 0], [-1, -1]], r: 0.645914159667201, s_t+1: [1, 0] 
 
             next state: [1, 0] 
             artifact to be printed next: [400, 700] 
 ------------------------------------------------------- 

##### epoch: 4.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 0] 
              artifact to be printed now: [400, 700] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 0], o_t: [[1, 1], [-1, 1], [0, 0], [-1, 1], [0, 0]], r: 0.542158991186414, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 5.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0]], [[0, 0], [1, 0], [-1, 0], [-1, -1], [1, -1]], [[0, 0], [0, 0], [1, -1], [-1, 1], [0, 0]], [[0, 0], [0, 0], [-1, 0], [1, 0], [-1, 0]], [[0, -1], [0, 1], [1, -1], [1, -1], [-1, 0]]], 
              Options states: [[[2, 4], [2, 4], [2, 4], [2, 4], [2, 4], [2, 4]], [[2, 4], [2, 4], [3, 4], [2, 4], [1, 3], [2, 2]], [[2, 4], [2, 4], [2, 4], [3, 3], [2, 4], [2, 4]], [[2, 4], [2, 4], [2, 4], [1, 4], [2, 4], [1, 4]], [[2, 4], [2, 3], [2, 4], [3, 3], [4, 2], [3, 2]]], 
              subgoals states: [[2, 4], [2, 2], [2, 4], [1, 4], [3, 2]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0]], r: 0.181301897917394, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 6.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0], [1, 0], [-1, 0], [-1, -1], [1, -1]], r: 0.200418982835436, s_t+1: [2, 2] 
 
             next state: [2, 2] 
             artifact to be printed next: [450, 800] 
 ------------------------------------------------------- 

##### epoch: 7.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 2] 
              artifact to be printed now: [450, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 2], o_t: [[0, 0], [0, 0], [1, -1], [-1, 1], [0, 0]], r: -2.50920121268171, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 8.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, 0], [0, 0], [-1, 0], [1, 0], [-1, 0]], r: 0.269199202302771, s_t+1: [1, 4] 
 
             next state: [1, 4] 
             artifact to be printed next: [400, 900] 
 ------------------------------------------------------- 

##### epoch: 9.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 4] 
              artifact to be printed now: [400, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 4], o_t: [[0, -1], [0, 1], [1, -1], [1, -1], [-1, 0]], r: 0.302666874211807, s_t+1: [3, 2] 
 
             next state: [3, 2] 
             artifact to be printed next: [500, 800] 
 ------------------------------------------------------- 

##### epoch: 10.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 2] 
              artifact to be printed now: [500, 800] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[-1, 1], [0, 1], [0, 0], [0, 0], [0, 0]], [[-1, 1], [0, -1], [1, 0], [0, 1], [-1, 1]], [[0, -1], [1, 1], [0, 1], [0, -1], [1, -1]], [[-1, 1], [-1, 0], [-1, 1], [-1, 0], [1, -1]], [[1, 1], [1, 0], [0, 1], [1, 1], [-1, 1]]], 
              Options states: [[[3, 2], [2, 3], [2, 4], [2, 4], [2, 4], [2, 4]], [[3, 2], [2, 3], [2, 2], [3, 2], [3, 3], [2, 4]], [[3, 2], [3, 1], [4, 2], [4, 3], [4, 2], [5, 1]], [[3, 2], [2, 3], [1, 3], [0, 4], [0, 4], [1, 3]], [[3, 2], [4, 3], [5, 3], [5, 4], [5, 5], [4, 6]]], 
              subgoals states: [[2, 4], [2, 4], [5, 1], [1, 3], [4, 6]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 2], o_t: [[-1, 1], [0, 1], [0, 0], [0, 0], [0, 0]], r: 0.609065122813726, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 11.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, 1], [0, -1], [1, 0], [0, 1], [-1, 1]], r: 0.275282667011429, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 12.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[0, -1], [1, 1], [0, 1], [0, -1], [1, -1]], r: 0.218771015054571, s_t+1: [5, 1] 
 
             next state: [5, 1] 
             artifact to be printed next: [600, 750] 
 ------------------------------------------------------- 

##### epoch: 13.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [5, 1] 
              artifact to be printed now: [600, 750] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [5, 1], o_t: [[-1, 1], [-1, 0], [-1, 1], [-1, 0], [1, -1]], r: -0.147529965842662, s_t+1: [1, 3] 
 
             next state: [1, 3] 
             artifact to be printed next: [400, 850] 
 ------------------------------------------------------- 

##### epoch: 14.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [1, 3] 
              artifact to be printed now: [400, 850] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [1, 3], o_t: [[1, 1], [1, 0], [0, 1], [1, 1], [-1, 1]], r: 0.207234880019635, s_t+1: [4, 6] 
 
             next state: [4, 6] 
             artifact to be printed next: [550, 1000] 
 ------------------------------------------------------- 

##### epoch: 15.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 6] 
              artifact to be printed now: [550, 1000] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[-1, -1], [-1, -1], [0, 0], [0, 0], [0, 0]], [[1, 0], [0, -1], [1, 1], [1, -1], [-1, -1]], [[1, -1], [0, 0], [-1, -1], [1, 1], [-1, -1]], [[0, 1], [-1, 0], [-1, 0], [-1, -1], [1, -1]], [[-1, 1], [1, 1], [1, -1], [0, -1], [-1, -1]]], 
              Options states: [[[4, 6], [3, 5], [2, 4], [2, 4], [2, 4], [2, 4]], [[4, 6], [5, 6], [5, 5], [5, 6], [5, 5], [4, 4]], [[4, 6], [5, 5], [5, 5], [4, 4], [5, 5], [4, 4]], [[4, 6], [4, 7], [3, 7], [2, 7], [1, 6], [2, 5]], [[4, 6], [3, 7], [4, 7], [5, 6], [5, 5], [4, 4]]], 
              subgoals states: [[2, 4], [4, 4], [4, 4], [2, 5], [4, 4]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 6], o_t: [[-1, -1], [-1, -1], [0, 0], [0, 0], [0, 0]], r: -0.0247691979331091, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 16.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[1, 0], [0, -1], [1, 1], [1, -1], [-1, -1]], r: 0.31309757403197, s_t+1: [4, 4] 
 
             next state: [4, 4] 
             artifact to be printed next: [550, 900] 
 ------------------------------------------------------- 

##### epoch: 17.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 4] 
              artifact to be printed now: [550, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 4], o_t: [[1, -1], [0, 0], [-1, -1], [1, 1], [-1, -1]], r: 0.50399624576688, s_t+1: [4, 4] 
 
             next state: [4, 4] 
             artifact to be printed next: [550, 900] 
 ------------------------------------------------------- 

##### epoch: 18.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 4] 
              artifact to be printed now: [550, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 4], o_t: [[0, 1], [-1, 0], [-1, 0], [-1, -1], [1, -1]], r: 0.511555278894249, s_t+1: [2, 5] 
 
             next state: [2, 5] 
             artifact to be printed next: [450, 950] 
 ------------------------------------------------------- 

##### epoch: 19.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 5] 
              artifact to be printed now: [450, 950] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 5], o_t: [[-1, 1], [1, 1], [1, -1], [0, -1], [-1, -1]], r: 0.370992697017298, s_t+1: [4, 4] 
 
             next state: [4, 4] 
             artifact to be printed next: [550, 900] 
 ------------------------------------------------------- 

##### epoch: 20.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 4] 
              artifact to be printed now: [550, 900] 


          Performing KDE calculations . . . . .


          Option creation: -----------------> 
              Options created: [[[-1, 0], [-1, 0], [0, 0], [0, 0], [0, 0]], [[-1, 0], [0, -1], [0, -1], [-1, 1], [1, -1]], [[1, 0], [1, -1], [1, 1], [-1, 0], [0, 0]], [[0, -1], [0, 1], [0, -1], [-1, 1], [-1, 1]], [[-1, 0], [1, 1], [1, 0], [1, 1], [-1, 0]]], 
              Options states: [[[4, 4], [3, 4], [2, 4], [2, 4], [2, 4], [2, 4]], [[4, 4], [3, 4], [3, 3], [3, 2], [2, 3], [3, 2]], [[4, 4], [5, 4], [5, 3], [5, 4], [4, 4], [4, 4]], [[4, 4], [4, 3], [4, 4], [4, 3], [3, 4], [2, 5]], [[4, 4], [3, 4], [4, 5], [5, 5], [5, 6], [4, 6]]], 
              subgoals states: [[2, 4], [3, 2], [4, 4], [2, 5], [4, 6]]

     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 4], o_t: [[-1, 0], [-1, 0], [0, 0], [0, 0], [0, 0]], r: 0.414854058111653, s_t+1: [2, 4] 
 
             next state: [2, 4] 
             artifact to be printed next: [450, 900] 
 ------------------------------------------------------- 

##### epoch: 21.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [2, 4] 
              artifact to be printed now: [450, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [2, 4], o_t: [[-1, 0], [0, -1], [0, -1], [-1, 1], [1, -1]], r: 0.342362085318558, s_t+1: [3, 2] 
 
             next state: [3, 2] 
             artifact to be printed next: [500, 800] 
 ------------------------------------------------------- 

##### epoch: 22.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [3, 2] 
              artifact to be printed now: [500, 800] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [3, 2], o_t: [[1, 0], [1, -1], [1, 1], [-1, 0], [0, 0]], r: 0.518985634993305, s_t+1: [4, 4] 
 
             next state: [4, 4] 
             artifact to be printed next: [550, 900] 
 ------------------------------------------------------- 

##### epoch: 23.0 -----------------------------  
      TAPRL feedback: ------------> 
              current state: [4, 4] 
              artifact to be printed now: [550, 900] 
     Brain update step: -----------------> 
 
             trajectory:---> s_t: [4, 4], o_t: [[0, -1], [0, 1], [0, -1], [-1, 1], [-1, 1]], r: 0.464294817206779, s_t+1: [2, 5] 
 
             next state: [2, 5] 
             artifact to be printed next: [450, 950] 
 ------------------------------------------------------- 

